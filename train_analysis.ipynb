{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the training result \n",
    "Training analysis is a a tool to evaluate the training result of lenet5 neural network. It could display the accuracy on training set and test set in graph. Or you can check the test datato show the image which is wrongly predicted in each batch of test data evaluation. \n",
    "\n",
    "## Define the variables to track\n",
    "There are 5 variables to monitor during the training.\n",
    "- Training accuracy\n",
    "- Test accuracy\n",
    "- Test images\n",
    "- Test labels\n",
    "- Prediction in test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import tf_general as tfg\n",
    "from cifar10 import cifar10\n",
    "cifar_data = cifar10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file_name = 'lenet_train_cifar10.log'\n",
    "def read_data(log_file_name):\n",
    "    train_accuracy = tfg.readlog(log_file_name,'accuracy')\n",
    "    test_accuracy = tfg.readlog(log_file_name,'test_accuracy')\n",
    "    loss = tfg.readlog(log_file_name,'loss')\n",
    "    test_index = tfg.readlog(log_file_name,'test_index')\n",
    "    output = tfg.readlog(log_file_name,'output')\n",
    "#print(test_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display training accuracy vs. test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_accuracy(train_accuracy, test_accuracy):\n",
    "    plt.rcParams['figure.dpi'] = 150    \n",
    "    step_train= []\n",
    "    step_train_accuracy = []\n",
    "    for item in train_accuracy:\n",
    "        step_train.append(item[0])\n",
    "        step_train_accuracy.append(item[1])\n",
    "        \n",
    "    plt.plot(step_train, step_train_accuracy)\n",
    "\n",
    "    step_test = []\n",
    "    step_test_accuracy = []\n",
    "    for item in test_accuracy:\n",
    "        step_test.append(item[0])\n",
    "        step_test_accuracy.append(item[1])\n",
    "    plt.plot(step_test, step_test_accuracy)\n",
    "\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_data(log_file_name)    \n",
    "show_accuracy(train_accuracy, test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_loss(loss):\n",
    "    plt.rcParams['figure.dpi'] = 150    \n",
    "    step_train= []\n",
    "    step_loss = []\n",
    "    for item in loss:\n",
    "        step_train.append(item[0])\n",
    "        step_loss.append(item[1])\n",
    "    plt.plot(step_train, step_loss)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "read_data(log_file_name)\n",
    "show_loss(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show test accuracy of specific training step\n",
    "Date structure of category_wrong_prediction  [[correct label index, wrong label index ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_test = []\n",
    "step_test_accuracy = []\n",
    "for item in test_accuracy:\n",
    "    step_test.append(item[0])\n",
    "    step_test_accuracy.append(item[1])\n",
    "    \n",
    "print('Available test steps:', step_test)\n",
    "step = int(input('Please input the test step in below number:'))\n",
    "if step in step_test: \n",
    "    plt.rcParams['figure.dpi'] = 16    \n",
    "    for item in test_accuracy:\n",
    "        if item[0] == step:\n",
    "            print('Test accuracy at train step '+ str(step)+': '+str(round(item[1]*100,2))+'%')\n",
    "       \n",
    "    prediction = []\n",
    "    for item in output:\n",
    "        if item[0] == step: \n",
    "            prediction.append(item[1])\n",
    "        \n",
    "    labels = []\n",
    "    for item in test_index:\n",
    "        if item[0] == step: \n",
    "            labels.append(item[1])\n",
    "    category_accuracy = {0:0.0,1:0.0,2:0.0,3:0.0,4:0.0,5:0.0,6:0.0,7:0.0,8:0.0,9:0.0}\n",
    "    category_wrong_prediction={0:[],1:[],2:[],3:[],4:[],5:[],6:[],7:[],8:[],9:[]}\n",
    "    i = 0\n",
    "    while i < len(labels) and i< len(prediction):\n",
    "        j = 0\n",
    "        while j < len(labels[i]):\n",
    "            if int(cifar_data.test_labels[int(labels[i][j])]) != int(prediction[i][j]):\n",
    "                category_wrong_prediction[cifar_data.test_labels[int(labels[i][j])]].append([int(labels[i][j]),int(prediction[i][j])])\n",
    "            else:\n",
    "                category_accuracy[cifar_data.test_labels[int(labels[i][j])]] += 1\n",
    "            j += 1        \n",
    "        #if key == 'q':\n",
    "            #break\n",
    "        i += 1\n",
    "    for k in range(9):\n",
    "        category_accuracy[k] /= 1000\n",
    "        print(cifar_data.label_dic[k] + ':' + str(round(category_accuracy[k]*100,2)) + '%')\n",
    "    key = input('Do you want to see those images with wrong label?Y/N')\n",
    "               \n",
    "    while key == 'y' or key == 'Y':\n",
    "        cat =  input('Input a category number:')\n",
    "        if int(cat) in [0,1,2,3,4,5,6,7,8,9]:\n",
    "            for item in category_wrong_prediction[int(cat)]:\n",
    "                plt.imshow(cifar_data.test_images[item[0]])\n",
    "                plt.show()\n",
    "                print('label: '+ cifar_data.label_dic[cifar_data.test_labels[item[0]]]) \n",
    "                print('prediction: '+cifar_data.label_dic[item[1]])\n",
    "                print('---------------------------------')\n",
    "        \n",
    "        key = input('Do you want to see another category?Y/N')\n",
    "else:\n",
    "    print('Invalid input.' + step + ' not exist in the list.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = input('Please input a category number:')\n",
    "distribution = {0:0.0,1:0.0,2:0.0,3:0.0,4:0.0,5:0.0,6:0.0,7:0.0,8:0.0,9:0.0}\n",
    "\n",
    "if int(key) in [0,1,2,3,4,5,6,7,8,9]:\n",
    "    for item in category_wrong_prediction[int(key)]:\n",
    "        distribution[item[1]] += 1\n",
    "for k in range(9):\n",
    "    print(cifar_data.label_dic[k]+':' + str(round(distribution[k]/len(category_wrong_prediction[int(key)])*100,2))+'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file_2 = 'lenet_train_cifar10_2.log'\n",
    "train_accuracy_2 = tfg.readlog(log_file_2,'accuracy')\n",
    "test_accuracy_2 = tfg.readlog(log_file_2,'test_accuracy')\n",
    "loss_2 = tfg.readlog(log_file_name,'loss')\n",
    "test_index_2 = tfg.readlog(log_file_2,'test_index')\n",
    "output_2 = tfg.readlog(log_file_2,'output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_accuracy(test_accuracy, test_accuracy_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cifar10 import cifar10\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = cifar10()\n",
    "batch_size=10\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.dpi'] = 28\n",
    "\n",
    "for i in range(5):\n",
    "    x, y,_ = data.get_train_batch(batch_size)\n",
    "    #print ('batch_x shape',np.shape(x))\n",
    "    for img in x:\n",
    "        plt.imshow(np.array(img))\n",
    "        plt.show()\n",
    "        print('-----------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
